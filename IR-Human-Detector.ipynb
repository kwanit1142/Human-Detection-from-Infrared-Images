{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os      \n",
    "import imutils\n",
    "import cv2\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage.color import rgb2grey\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Image and Resizing to Standard Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(row_id, root=r\"Complete-Path-of-Image-Dataset-Directory\"):     # Path like C:/Users/cook/Desktop/IR/\n",
    "    \n",
    "    filename = \"{}.png\".format(row_id)                   # Converts an image number into the file path where the image is located\n",
    "    file_path = os.path.join(root, filename)\n",
    "    imag = Image.open(file_path)                         # Opens the image, and returns the image as a numpy array\n",
    "    img=imag.resize((64,128))                            # Resize the original Image\n",
    "    return np.array(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting HOG Features from Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(img):                                                 \n",
    "    \n",
    "    color_features = img.flatten()                                                    # flatten three channel color image\n",
    "    grey_image = rgb2grey(img)                                                        # convert image to greyscale\n",
    "    hog_features = hog(grey_image, block_norm='L2-Hys', pixels_per_cell=(2,2))        # get HOG features from greyscale image\n",
    "    flat_features = np.hstack(hog_features)                                           # combine color and hog features into a single array\n",
    "    return flat_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating HOG Features Matrix for Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_matrix(label_dataframe): \n",
    "    \n",
    "    c=1\n",
    "    features_list = []                                   # List of Features of an Image\n",
    "    for img_id in label_dataframe.index:\n",
    "        img = get_image(img_id)                          # load image\n",
    "        image_features = create_features(img)            # get features for image\n",
    "        features_list.append(image_features)\n",
    "        print(c)                                         # Displays the count of Images converted to Vector\n",
    "        c+=1\n",
    "    feature_matrix = np.array(features_list)             # convert list of arrays into a matrix\n",
    "    return feature_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying PCA to reduce Dimensionality of Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcca(feature_matrix):\n",
    "                                   \n",
    "    print('Feature matrix shape is: ', feature_matrix.shape)           # get shape of feature matrix\n",
    "    ss = StandardScaler()                                              # define standard scaler\n",
    "    human_stand = ss.fit_transform(feature_matrix)                     # run this on our feature matrix\n",
    "    pca = PCA(n_components=50)                                         # set the number of components wisely, maybe less than 75\n",
    "    human_pca = pca.fit_transform(human_stand)                         # use fit_transform to run PCA on our standardized matrix\n",
    "    print('PCA matrix shape is: ', human_pca.shape)                    # look at new shape\n",
    "    return human_pca\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sliding Window Mechanism running throughout an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, stepSize, windowSize):\n",
    "    \n",
    "    for y in range(0, image.shape[0], stepSize):                                  # slide a window across the image\n",
    "        for x in range(0, image.shape[1], stepSize):                              # yield the current window\n",
    "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Maximum Suppression for removing False Positive Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression_fast(boxes, overlapThresh):\n",
    "    \n",
    "    if len(boxes) == 0:                                                  # if there are no boxes, return an empty list\n",
    "        return []\n",
    "    if boxes.dtype.kind == \"i\":                                          # if the bounding boxes integers, convert them to floats --\n",
    "        boxes = boxes.astype(\"float\")                                    # this is important since we'll be doing a bunch of divisions\n",
    "    pick = []                                                            # initialize the list of picked indexes\n",
    "    x1 = boxes[:,0]                                                      # grab the coordinates of the bounding boxes\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)                                 # compute the area of the bounding boxes \n",
    "    idxs = np.argsort(y2)                                                # sort the bounding boxes by the bottom-right y-coordinate of the bounding box\n",
    "    while len(idxs) > 0:                                                 # keep looping while some indexes still remain in the indexes list\n",
    "        last = len(idxs) - 1                                             # grab the last index in the indexes list  \n",
    "        i = idxs[last]                                                   \n",
    "        pick.append(i)                                                   # add the index value to the list of picked indexes\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])                         # find the largest (x, y) coordinates for the start of the bounding box\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])                         # find the smallest (x, y) coordinates for the end of the bounding box\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)                                 # compute the width of the bounding box\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)                                 # compute the height of the bounding box\n",
    "        overlap = (w * h) / area[idxs[:last]]                            # compute the ratio of overlap\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],                   # delete all indexes from the index list that have\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "    return boxes[pick].astype(\"int\")                                     # return only the bounding boxes that were picked using the integer data type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Procedure for Image Dataset, using Support Vector Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = pd.read_csv(r\"Complete-Path-Of-Image-Label-csv-File-saved-in-Same-Image-Dataset-Directory\", index_col=0)     # Path like C:/Users/cook/Desktop/IR/IR.csv\n",
    "feature_matrix = create_feature_matrix(labels)                                                                        # run create_feature_matrix on our dataframe of images\n",
    "hp=pcca(feature_matrix)                                                                                               # Reduced Matrix of Image Vectors\n",
    "X_train = pd.DataFrame(hp)                                 \n",
    "y_train = pd.Series(labels.label.values)                                       # Access the labels of Training Images\n",
    "pd.Series(y_train).value_counts()                                              # look at the distrubution of labels in the train set\n",
    "svm = SVC(kernel='rbf', probability=True, random_state=42)                     # define support vector classifier\n",
    "svm.fit(X_train, y_train)                                                      # fit model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Trained Model to Detect Human in a Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagee = cv2.imread(r\"Complete-Path-Of-Test-Image\")                                         \n",
    "scale_percent = 200                                                                         # percent of original size\n",
    "width = int(imagee.shape[1] * scale_percent / 100)\n",
    "height = int(imagee.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)                                                                       # New dimensions of Image Window\n",
    "image = cv2.resize(imagee, dim, interpolation = cv2.INTER_AREA)                             # resize image\n",
    "(winW , WinH) = (64 , 128)                                                                  # Dimensions of Sliding Window\n",
    "t=[]                                                                                        # Feature Matrix for test image portions\n",
    "k=[]                                                                                        # Indexes corresponding to image portions\n",
    "for (x, y, window) in sliding_window(image, stepSize=16, windowSize=(winW, winH)):          # loop over the sliding window for each layer of the pyramid\n",
    "    if window.shape[0] != winH or window.shape[1] != winW:                                  # if the window does not meet our desired window size, ignore it\n",
    "        continue                                                                                            \n",
    "    clone = image.copy()\n",
    "    op=clone[y:y+winH,x:x+winW]\n",
    "    f=create_features(op)\n",
    "    t.append(f)\n",
    "    k.append([x,y])\n",
    "    cv2.rectangle(clone, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Window\", clone)\n",
    "    cv2.waitKey(1)\n",
    "    time.sleep(0.025)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# THIS IS WHERE YOU WOULD PROCESS YOUR WINDOW, SUCH AS APPLYING A MACHINE LEARNING CLASSIFIER TO CLASSIFY THE CONTENTS OF THE WINDOW\n",
    "# since we do not have a classifier, we'll just draw the window\n",
    "\n",
    "hpp=pcca(t)\n",
    "x_p=pd.DataFrame(hpp)\n",
    "y_p=svm.predict(x_p)\n",
    "pp=list(y_p)                                                                                # Predict the portions where human is detected\n",
    "clon = image.copy()\n",
    "nn=[]                                                                                       # List of indexes of Human Detection Portions\n",
    "for i in range(0,len(pp)):\n",
    "    if pp[i]==1.0:\n",
    "        x=k[i][0]\n",
    "        y=k[i][1]\n",
    "        nn.append([x,y,x+winW,y+winH])\n",
    "        cv2.rectangle(clon, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Window\", clon)\n",
    "        cv2.waitKey(50)\n",
    "        time.sleep(0.025)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "ll=non_max_suppression_fast(np.array(nn),0.4)                                              # Applied Non-Max Suppression on Human Detected portions\n",
    "l=list(ll)                                                                                 # List of Indexes of Actual Human Regions \n",
    "clo=image.copy()\n",
    "for kl in l:\n",
    "    cv2.rectangle(clo, (kl[0], kl[1]), (kl[2],kl[3]), (0, 255, 0), 1)                      # Display the most probable Detection Regions out of False Positives\n",
    "    cv2.imshow(\"Window\", clo)\n",
    "    cv2.waitKey(0)\n",
    "    time.sleep(0.025)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
